{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GX7XRt4hYdR"
   },
   "source": [
    "# Dataset / Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNulj-OkiyNS",
    "outputId": "45ca676c-7227-41f4-a07d-e5ade57e91ae"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxz__6ejiJAJ"
   },
   "source": [
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dI8KkkTwpviW",
    "outputId": "bd39a89d-aecf-4af2-dc90-cfe1c2ee579a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"Versions des librairies importantes :\")\n",
    "print(f\"  Librosa:      {librosa.__version__}\")\n",
    "print(f\"  NumPy:        {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IU2Vj7KViOM6"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXVxiWf4qeXr",
    "outputId": "4c184e8d-1f2a-4bee-8b37-6f3b0dafdd02"
   },
   "outputs": [],
   "source": [
    "dataset_path = \"/content/drive/MyDrive/Artishow/Data/genres_original\"\n",
    "\n",
    "subfolders = os.listdir(dataset_path)\n",
    "print(\"Sous-dossiers:\", subfolders)\n",
    "\n",
    "audio_files = glob.glob(f\"{dataset_path}/**/*.wav\", recursive=True)\n",
    "print(f\"Nombre de fichiers audio: {len(audio_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYaFGNiqiVgz"
   },
   "source": [
    "# PHASE 1 : Classificateurs de genres - Genre Classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGfU9T28idlQ"
   },
   "source": [
    "## Approche 1 : Machine Learning Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtRRFncZn589"
   },
   "source": [
    "### Extraction des features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "HGIsg96zp8E6",
    "outputId": "0e444cc1-575f-41ab-869d-c466984842b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import os\n",
    "import zipfile\n",
    "from IPython.display import FileLink\n",
    "\n",
    "X = [] #features\n",
    "Y = [] #labels\n",
    "\n",
    "def extract_features(file_path, duration=30, sr=22050):\n",
    "    y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "\n",
    "    # Fonction pour extraire la moyenne et l'écart-type\n",
    "    def stats(feature):\n",
    "        return list(map(float, np.mean(feature, axis=1))) + list(map(float, np.std(feature, axis=1)))\n",
    "\n",
    "    # Extraction des features\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    print(len(mfcc[0]))\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    zero_crossing = librosa.feature.zero_crossing_rate(y=y)\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "    # Construction du vecteur de features\n",
    "    features = []\n",
    "    for f in [mfcc, rms, spectral_centroid, bandwidth, contrast, flatness, rolloff, tonnetz, zero_crossing]:\n",
    "        features.extend(stats(f))\n",
    "    features.append(float(tempo))\n",
    "\n",
    "    genre = (os.path.splitext(os.path.basename(file_path))[0]).split('.')[0]\n",
    "    print(\"Genre connu : \" + genre)\n",
    "    print(\"\")\n",
    "\n",
    "    X.append(features)\n",
    "    Y.append(genre)\n",
    "\n",
    "i = 0\n",
    "for file in audio_files:\n",
    "    i+=1\n",
    "    print(i)\n",
    "    extract_features(file)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df['genre'] = Y\n",
    "df['genre'] = df['genre'].astype('category')\n",
    "genre_mapping = dict(enumerate(df['genre'].cat.categories))\n",
    "df['genre'] = df['genre'].astype('category').cat.codes\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop(columns=['genre'],), df['genre'], test_size=0.2, random_state = 42,stratify = Y)\n",
    "print(Y_train.tolist())\n",
    "print(Y_test.tolist())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML'\n",
    "\n",
    "# Sauvegarde des fichiers\n",
    "joblib.dump(X_train, os.path.join(save_dir, \"X_train.pkl\"))\n",
    "joblib.dump(X_test, os.path.join(save_dir, \"X_test.pkl\"))\n",
    "joblib.dump(Y_train, os.path.join(save_dir, \"Y_train.pkl\"))\n",
    "joblib.dump(Y_test, os.path.join(save_dir, \"Y_test.pkl\"))\n",
    "joblib.dump(scaler, os.path.join(save_dir, \"scaler.pkl\"))\n",
    "joblib.dump(genre_mapping, os.path.join(save_dir, \"genre_mapping.pkl\"))\n",
    "\n",
    "files_to_zip = [\n",
    "    \"X_train.pkl\",\n",
    "    \"X_test.pkl\",\n",
    "    \"Y_train.pkl\",\n",
    "    \"Y_test.pkl\",\n",
    "    \"scaler.pkl\",\n",
    "    \"genre_mapping.pkl\"\n",
    "]\n",
    "\n",
    "zip_filename = \"features_data.zip\"\n",
    "zip_path = os.path.join(save_dir, zip_filename)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"w\") as zipf:\n",
    "    for filename in files_to_zip:\n",
    "        file_path = os.path.join(save_dir, filename)\n",
    "        zipf.write(file_path, arcname=filename)\n",
    "\n",
    "# Lien pour télécharger\n",
    "display(FileLink(zip_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qq0vPDU0ERt0"
   },
   "outputs": [],
   "source": [
    "# Stocker les features/labels\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import os\n",
    "import zipfile\n",
    "from IPython.display import FileLink\n",
    "\n",
    "X = [] #features\n",
    "Y = [] #labels\n",
    "\n",
    "def extract_features(file_path, duration=30, sr=22050):\n",
    "    y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "\n",
    "    # Fonction pour extraire la moyenne et l'écart-type\n",
    "    def stats(feature):\n",
    "        return list(map(float, np.mean(feature, axis=1))) + list(map(float, np.std(feature, axis=1)))\n",
    "\n",
    "    # Extraction des features\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    print(len(mfcc[0]))\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    zero_crossing = librosa.feature.zero_crossing_rate(y=y)\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "    # Construction du vecteur de features\n",
    "    features = []\n",
    "    for f in [mfcc, rms, spectral_centroid, bandwidth, contrast, flatness, rolloff, tonnetz, zero_crossing]:\n",
    "        features.extend(stats(f))\n",
    "    features.append(float(tempo))\n",
    "\n",
    "    genre = (os.path.splitext(os.path.basename(file_path))[0]).split('.')[0]\n",
    "    print(\"Genre connu : \" + genre)\n",
    "\n",
    "    \"\"\"print(np.array(features, dtype=np.float32))\"\"\"  # Conversion finale\n",
    "    print(\"\")\n",
    "\n",
    "    X.append(features)\n",
    "    Y.append(genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeHW8wFO16Wp"
   },
   "source": [
    "### Fichiers Préentrainés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbYk_p_cX1nW",
    "outputId": "4292a6b8-c07e-442d-bcf7-7e39888be811"
   },
   "outputs": [],
   "source": [
    "# Fichiers Préentrainés (GTZAN)\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "X_train = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/X_train.pkl')\n",
    "Y_train = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/Y_train.pkl')\n",
    "X_test = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/X_test.pkl')\n",
    "Y_test = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/Y_test.pkl')\n",
    "genre_mapping = {0: 'blues', 1: 'classical', 2: 'country', 3: 'disco', 4: 'hiphop', 5: 'jazz', 6: 'metal', 7: 'pop', 8: 'reggae', 9: 'rock'}\n",
    "\n",
    "print(Y_train)\n",
    "print(genre_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6lWbx1RKPp6",
    "outputId": "a409be5c-c0c4-4c9c-8ea5-0e2459d9856d"
   },
   "outputs": [],
   "source": [
    "# Fichiers Préentrainés (MTG-JAMENDO)\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "X_train_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/X_train.pkl')\n",
    "Y_train_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/Y_train.pkl')\n",
    "X_test_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/X_test.pkl')\n",
    "Y_test_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/Y_test.pkl')\n",
    "mood_mapping = {0: 'dark', 1: 'deep', 2: 'dream', 3: 'emotional', 4: 'epic', 5: 'happy', 6: 'motivational', 7: 'relaxing', 8: 'romantic', 9: 'sad'}\n",
    "\n",
    "print(Y_train_mood)\n",
    "print(mood_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuLYtN3En8if"
   },
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k92P_t3sqnj7"
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#Genre\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, Y_train)\n",
    "save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML'\n",
    "joblib.dump(model, os.path.join(save_dir, \"svm_model.pkl\"))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(\"Prédiction (Genre) : \" + str(pred))\n",
    "\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "print(f'Précision (Genre) : {accuracy:.2%}')\n",
    "\n",
    "\n",
    "#Mood\n",
    "model_mood = SVC(kernel='linear')\n",
    "model_mood.fit(X_train_mood, Y_train_mood)\n",
    "save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML_moods'\n",
    "joblib.dump(model_mood, os.path.join(save_dir, \"svm_model_mood.pkl\"))\n",
    "\n",
    "pred_mood = model_mood.predict(X_test_mood)\n",
    "print(\"Prédiction (Mood) : \" + str(pred_mood))\n",
    "\n",
    "accuracy = accuracy_score(Y_test_mood, pred_mood)\n",
    "print(f'Précision (Mood) : {accuracy:.2%}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ys1qWM6XqqZl"
   },
   "outputs": [],
   "source": [
    "#LogisticRegression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Mood\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML'\n",
    "joblib.dump(model, os.path.join(save_dir, \"LogisticRegModel.pkl\"))\n",
    "\n",
    "print(\"Prédiction (Genre) : \" + str(pred))\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "print(f'Précision (Genre) : {accuracy:.2%}')\n",
    "\n",
    "\n",
    "#Genre\n",
    "model_mood = LogisticRegression()\n",
    "model_mood.fit(X_train_mood, Y_train_mood)\n",
    "\n",
    "pred_mood = model_mood.predict(X_test_mood)\n",
    "save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML_moods'\n",
    "joblib.dump(model_mood, os.path.join(save_dir, \"LogisticRegModel_mood.pkl\"))\n",
    "\n",
    "print(\"Prédiction (Genre) : \" + str(pred_mood))\n",
    "accuracy = accuracy_score(Y_test_mood, pred_mood)\n",
    "print(f'Précision (Genre) : {accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LfA5irJqsrK"
   },
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#Genre\n",
    "rf_model = RandomForestClassifier(n_estimators=103, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, Y_train)\n",
    "Y_pred = rf_model.predict(X_test)\n",
    "save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML'\n",
    "joblib.dump(rf_model, os.path.join(save_dir, \"rf_model.pkl\"))\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Prédiction (Genre)\", Y_pred)\n",
    "print(f\"Précision (Genre) : {accuracy:.2%}\")\n",
    "\n",
    "#Mood\n",
    "rf_model_mood = RandomForestClassifier(n_estimators=103, random_state=42)\n",
    "\n",
    "rf_model_mood.fit(X_train_mood, Y_train_mood)\n",
    "Y_pred_mood = rf_model_mood.predict(X_test_mood)\n",
    "save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML_moods'\n",
    "joblib.dump(rf_model, os.path.join(save_dir, \"rf_model_mood.pkl\"))\n",
    "\n",
    "accuracy = accuracy_score(Y_test_mood, Y_pred_mood)\n",
    "print(\"Prédiction (Mood)\", Y_pred_mood)\n",
    "print(f\"Précision (Mood) : {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBNNqW9PquhK"
   },
   "outputs": [],
   "source": [
    "#GradientBoosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Genre\n",
    "model_gbt = GradientBoostingClassifier()\n",
    "model_gbt.fit(X_train, Y_train)\n",
    "save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML'\n",
    "joblib.dump(model_gbt, os.path.join(save_dir, \"gbt_model.pkl\"))\n",
    "Y_pred_gbt = model_gbt.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, Y_pred_gbt)\n",
    "print(\"Prédiction (Genre)\", Y_pred)\n",
    "print(f\"Précision (Genre)): {accuracy:.2%}\")\n",
    "\n",
    "#Mood\n",
    "model_gbt_mood = GradientBoostingClassifier()\n",
    "model_gbt_mood.fit(X_train_mood, Y_train_mood)\n",
    "save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML_moods'\n",
    "joblib.dump(model_gbt_mood, os.path.join(save_dir, \"gbt_model_mood.pkl\"))\n",
    "Y_pred_gbt_mood = model_gbt_mood.predict(X_test_mood)\n",
    "accuracy = accuracy_score(Y_test_mood, Y_pred_gbt_mood)\n",
    "print(\"Prédiction (Mood)\", Y_pred_gbt_mood)\n",
    "print(f\"Précision (Mood): {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCASpaKQqwbw"
   },
   "outputs": [],
   "source": [
    "#K-Nearest Neighbors\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Genre\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "pred_k = knn.predict(X_test)\n",
    "save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML'\n",
    "joblib.dump(knn, os.path.join(save_dir, \"knn_model.pkl\"))\n",
    "\n",
    "print(\"Prédiction (Genre) :\" + str(pred_k))\n",
    "accuracy = accuracy_score(Y_test, pred_k)\n",
    "print(f'Précision (Genre): {accuracy:.2%}')\n",
    "\n",
    "\n",
    "#Mood\n",
    "knn_mood = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_mood.fit(X_train_mood, Y_train_mood)\n",
    "\n",
    "pred_k_mood = knn_mood.predict(X_test_mood)\n",
    "save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML_moods'\n",
    "joblib.dump(knn, os.path.join(save_dir, \"knn_model_mood.pkl\"))\n",
    "\n",
    "print(\"Prédiction (Mood) :\" + str(pred_k_mood))\n",
    "accuracy = accuracy_score(Y_test_mood, pred_k_mood)\n",
    "print(f'Précision (Mood): {accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UHdOKUGYHQM"
   },
   "outputs": [],
   "source": [
    "#Version 2 pas fini : Pour tester sur une musique de son choix - To try on a chosen music\n",
    "\n",
    "import joblib\n",
    "\n",
    "X_genre = []\n",
    "X_mood = []\n",
    "\n",
    "def pred_musique2(file_path, model_genre):\n",
    "\n",
    "  extract_features(file_path, duration=30, sr=22050)\n",
    "  df_test = pd.DataFrame(X)\n",
    "  scaler = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/scaler.pkl')\n",
    "  df_test_scaled = scaler.transform(df_test)\n",
    "  prediction = model.predict(df_test_scaled)\n",
    "  print(f\"Prédiction (Genre): {genre_mapping[int(prediction[0])]}\")\n",
    "  X.clear()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pred_musique(file_path, model):\n",
    "  extract_features(file_path, duration=30, sr=22050)\n",
    "  df_test = pd.DataFrame(X)\n",
    "  scaler = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/scaler.pkl')\n",
    "  df_test_scaled = scaler.transform(df_test)\n",
    "  prediction = model.predict(df_test_scaled)\n",
    "  print(f\"Prédiction (Genre): {genre_mapping[int(prediction[0])]}\")\n",
    "  X.clear()\n",
    "  return genre_mapping[int(prediction[0])]\n",
    "\n",
    "\n",
    "svm_model = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/svm_model.pkl')\n",
    "knn_model = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/knn_model.pkl')\n",
    "gbt_model = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/gbt_model.pkl')\n",
    "rf_model = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/rf_model.pkl')\n",
    "LogisticRegModel = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/LogisticRegModel.pkl')\n",
    "\n",
    "svm_model_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/svm_model_mood.pkl')\n",
    "knn_model_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/knn_model_mood.pkl')\n",
    "gbt_model_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/gbt_model_mood.pkl')\n",
    "rf_model_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/rf_model_mood.pkl')\n",
    "LogisticRegModel_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/LogisticRegModel_mood.pkl')\n",
    "\n",
    "def pred_globale(file_path):\n",
    "  print(\"==== SVM ====\")\n",
    "  pred_musique2(file_path, svm_model)\n",
    "  print(\"==== KNN ====\")\n",
    "  pred_musique2(file_path, knn_model)\n",
    "  print(\"==== Gradient Boosting ====\")\n",
    "  pred_musique2(file_path, gbt_model)\n",
    "  print(\"==== Random Forest ====\")\n",
    "  pred_musique2(file_path, rf_model)\n",
    "  print(\"==== Logistic Regression ====\")\n",
    "  pred_musique2(file_path, LogisticRegModel)\n",
    "\n",
    "pred_globale('/content/drive/MyDrive/Artishow/Musique perso/Dua Lipa - Houdini.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtjchEEoAK-R"
   },
   "outputs": [],
   "source": [
    "#V1 pour tester sur une musique de son choix (GENRE)\n",
    "\n",
    "X_genre = []\n",
    "X_mood = []\n",
    "\n",
    "def pred_musique_2(file_path, model_genre, model_mood):\n",
    "\n",
    "  extract_features(file_path, duration=30, sr=22050)\n",
    "\n",
    "  #Genre\n",
    "  df_test = pd.DataFrame(X_genre)\n",
    "  scaler = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/scaler.pkl')\n",
    "  df_test_scaled = scaler.transform(df_test)\n",
    "  prediction = model_genre.predict(df_test_scaled)\n",
    "  print(f\"Prédiction (Genre): {genre_mapping[int(prediction[0])]}\")\n",
    "  X_genre.clear()\n",
    "\n",
    "  #Mood\n",
    "  df_test_mood = pd.DataFrame(X_mood)\n",
    "  scaler_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/scaler.pkl')\n",
    "  df_test_scaled_mood = scaler_mood.transform(df_test_mood)\n",
    "  prediction = model_mood.predict(df_test_scaled_mood)\n",
    "  print(prediction)\n",
    "  print(f\"Prédiction (Mood): {mood_mapping[int(prediction[0])]}\")\n",
    "  X_mood.clear()\n",
    "\n",
    "\n",
    "def pred_musique(file_path, model):\n",
    "  extract_features(file_path, duration=30, sr=22050)\n",
    "  df_test = pd.DataFrame(X)\n",
    "  scaler = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/scaler.pkl')\n",
    "  df_test_scaled = scaler.transform(df_test)\n",
    "  prediction = model.predict(df_test_scaled)\n",
    "  print(f\"Prédiction (Genre): {genre_mapping[int(prediction[0])]}\")\n",
    "  X.clear()\n",
    "  return genre_mapping[int(prediction[0])]\n",
    "\n",
    "def pred_musique_mood(file_path, model):\n",
    "  extract_features(file_path, duration=30, sr=22050)\n",
    "  df_test = pd.DataFrame(X)\n",
    "  scaler = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/scaler.pkl')\n",
    "  df_test_scaled = scaler.transform(df_test)\n",
    "  prediction = model.predict(df_test_scaled)\n",
    "  print(prediction)\n",
    "  print(f\"Prédiction (Mood) : {mood_mapping[int(prediction[0])]}\")\n",
    "  X.clear()\n",
    "  return mood_mapping[int(prediction[0])]\n",
    "\n",
    "svm_model = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/svm_model.pkl')\n",
    "knn_model = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/knn_model.pkl')\n",
    "gbt_model = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/gbt_model.pkl')\n",
    "rf_model = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/rf_model.pkl')\n",
    "LogisticRegModel = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/LogisticRegModel.pkl')\n",
    "\n",
    "svm_model_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/svm_model_mood.pkl')\n",
    "knn_model_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/knn_model_mood.pkl')\n",
    "gbt_model_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/gbt_model_mood.pkl')\n",
    "rf_model_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/rf_model_mood.pkl')\n",
    "LogisticRegModel_mood = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/LogisticRegModel_mood.pkl')\n",
    "\n",
    "def pred_globale(file_path):\n",
    "  print(\"==== SVM ====\")\n",
    "  pred_musique(file_path, svm_model)\n",
    "  pred_musique_mood(file_path, svm_model_mood)\n",
    "  print(\"==== KNN ====\")\n",
    "  pred_musique(file_path, knn_model)\n",
    "  pred_musique_mood(file_path, knn_model_mood)\n",
    "  print(\"==== Gradient Boosting ====\")\n",
    "  pred_musique(file_path, gbt_model)\n",
    "  pred_musique_mood(file_path, gbt_model_mood)\n",
    "  print(\"==== Random Forest ====\")\n",
    "  pred_musique(file_path, rf_model)\n",
    "  pred_musique_mood(file_path, rf_model_mood)\n",
    "  print(\"==== Logistic Regression ====\")\n",
    "  pred_musique(file_path, LogisticRegModel)\n",
    "  pred_musique_mood(file_path, LogisticRegModel_mood)\n",
    "\n",
    "pred_globale('/content/drive/MyDrive/Artishow/Musique perso/Dua Lipa - Houdini.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcCehqTTncMS"
   },
   "source": [
    "## Approche 2 : CNN + Spectrograms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njju_yyBpZjA"
   },
   "source": [
    "### Conversion en spectrogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1D20sWBq9NC"
   },
   "outputs": [],
   "source": [
    "#Spectrogramme\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def audio_to_mel_spec(audio, save_path, sr=22050, n_mels=128, hop_length=512):\n",
    "    y, sr = librosa.load(audio, sr=sr, duration=30)\n",
    "    melspec = librosa.feature.melspectrogram(y=y, sr=sr,n_mels=n_mels\n",
    "                                             , hop_length=hop_length)\n",
    "    melspec_db = librosa.power_to_db(melspec, ref=np.max)\n",
    "\n",
    "    # Plot & save spectrogram\n",
    "    plt.figure(figsize=(4.32, 2.88), dpi=100)  # image 224x224 pixels\n",
    "    #librosa.display.specshow(melspec_db)  # ou 'inferno'\n",
    "    plt.imshow(melspec_db, aspect='auto', origin='lower', cmap='magma', vmin=-42, vmax=0)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "\n",
    "output_dir = \"/content/drive/MyDrive/Artishow/spectrogramStorage\"\n",
    "i=0\n",
    "\n",
    "for audio in audio_files[:1000]:\n",
    "    i+=1\n",
    "    print(i)\n",
    "    file_name = os.path.basename(audio).replace('.mp3','.png').replace('.wav','.png')\n",
    "    save_path = os.path.join(output_dir, file_name)\n",
    "    print(file_name)\n",
    "    audio_to_mel_spec(audio, save_path)\n",
    "\n",
    "shutil.make_archive(\"/kaggle/working/dataset_spectrograms\", 'zip', output_dir)\n",
    "print(\"fichier créé pret a download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "ZGcQpXGFrOQx",
    "outputId": "bd80f201-02fc-4769-a2e5-4e7ebf0dcae0"
   },
   "outputs": [],
   "source": [
    "#Mettre en forme les données\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "spectrograms_dir = '/content/drive/MyDrive/Artishow/Data/images_original'\n",
    "data = []\n",
    "\n",
    "for genre in os.listdir(spectrograms_dir):\n",
    "    genre_dir = os.path.join(spectrograms_dir, genre)\n",
    "    if not os.path.isdir(genre_dir):\n",
    "        continue\n",
    "    for file in os.listdir(genre_dir):\n",
    "        if file.endswith(\".png\"):\n",
    "            file_path = os.path.join(genre_dir, file)\n",
    "            data.append([file_path, genre])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"filename\", \"genre\"])\n",
    "display(df.head())\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 32\n",
    "DATASET_DIR = \"dataset_spectrograms\"\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"genre\",\n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"training\"\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"genre\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"validation\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w09QkToHphoC"
   },
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "Aw9PWY-urSq9",
    "outputId": "62acc491-1cd1-4f35-d589-29a1c07e4c82"
   },
   "outputs": [],
   "source": [
    "#VGG-16\n",
    "\n",
    "import os\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "filepath = \"/content/drive/MyDrive/Artishow/Modèle/IA/vgg16_weights_tf_dim_ordering_tf_kernels_notop (1).h5\"\n",
    "base_model = VGG16(weights=filepath,\n",
    "                include_top=False,\n",
    "                input_shape=((224,224, 3))\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(df['genre'].nunique(),activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "model.save(\"/content/drive/MyDrive/Artishow/Modèle/IA/vgg16_genre_classification.h5\")\n",
    "\n",
    "loss, accuracy = model.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGBtr3_ynbYT",
    "outputId": "533292a0-fd9b-4bd0-ce96-651b7c2b36af"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = tf.keras.models.load_model(\"/content/drive/MyDrive/Artishow/Modèle/IA/vgg16_genre_classification.h5\")\n",
    "pred = model.predict(val_generator)\n",
    "\n",
    "true_classes = val_generator.classes\n",
    "pred_classes = np.argmax(pred, axis=1)\n",
    "acc = accuracy_score(true_classes, pred_classes)\n",
    "print(f\"Accuracy sur validation set : {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "cro4kCGOnb5E",
    "outputId": "a3b51eb8-144d-4116-88ab-bf55c4a6d66b"
   },
   "outputs": [],
   "source": [
    "audio_to_mel_spec(\"/content/drive/MyDrive/Artishow/Musique perso/Dua Lipa - Houdini.mp3\", \"/content/drive/MyDrive/Artishow/spectrogramStorage/MusiquePerso/specPerso\")\n",
    "import keras.preprocessing.image as image\n",
    "# Charger l’image et la préparer pour le modèle\n",
    "\n",
    "def load_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.  # Si tu as utilisé rescale=1./255\n",
    "    return img_array\n",
    "\n",
    "# Charger ton modèle entraîné\n",
    "model = tf.keras.models.load_model(\"/content/drive/MyDrive/Artishow/Modèle/IA/vgg16_genre_classification.h5\")\n",
    "\n",
    "# Exemple d'audio à prédire\n",
    "spec_path = \"/content/drive/MyDrive/Artishow/spectrogramStorage/MusiquePerso/specPerso.png\"\n",
    "img_array = load_image(spec_path)\n",
    "\n",
    "# Prédiction\n",
    "prediction = model.predict(img_array)\n",
    "print(prediction)\n",
    "predicted_indices = np.argsort(prediction)[0][-2:][::-1]\n",
    "print(f\"Genres prédits : {predicted_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlLQ7l74nhOm"
   },
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HgDoWXu6rVyb",
    "outputId": "a3fde7cc-454a-44b5-aa0a-247f71461b44"
   },
   "outputs": [],
   "source": [
    "#Benchmark\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC(kernel='linear', probability=True),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=103, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "def compute_f1_score(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "def compute_auc(y_true, y_prob):\n",
    "    if y_prob is not None:\n",
    "        try:\n",
    "            y_true_bin = label_binarize(y_true, classes=np.unique(y_true))\n",
    "            return roc_auc_score(y_true_bin, y_prob, average='weighted', multi_class='ovr')\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "print(\"Réponse :\", Y_test.tolist())\n",
    "\n",
    "#Entrainement\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    prob = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    accuracy = accuracy_score(Y_test, pred)\n",
    "    f1 = compute_f1_score(Y_test, pred)\n",
    "    auc = compute_auc(Y_test, prob)\n",
    "    print(f\"Prédiction {name} : {pred}\")\n",
    "    results.append((name, accuracy, f1, auc))\n",
    "\n",
    "#Affichage\n",
    "results_df = pd.DataFrame(results, columns=[\"Modele\", \"Precision\", \"F1-Score\", \"AUC\"])\n",
    "print(results_df.sort_values(by=\"F1-Score\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PUK_Yw9Up9Ah",
    "outputId": "a4434053-e592-4206-e1d5-7f1e13fb888b"
   },
   "outputs": [],
   "source": [
    "#Matrice de confusion\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "use_mood = False  # Mets False pour genre\n",
    "\n",
    "mood_mapping = {0: 'dark', 1: 'deep', 2: 'dream', 3: 'emotional', 4: 'epic', 5: 'happy', 6: 'motivational', 7: 'relaxing', 8: 'romantic', 9: 'sad'}\n",
    "genre_mapping = {0: 'blues', 1: 'classical', 2: 'country', 3: 'disco', 4: 'hiphop', 5: 'jazz', 6: 'metal', 7: 'pop', 8: 'reggae', 9: 'rock'}\n",
    "\n",
    "mapping = mood_mapping if use_mood else genre_mapping\n",
    "labels = [mapping[cle] for cle in mapping]\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC(kernel='linear', probability=True),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=103, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(Y_test, pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", # fmt=\"d\" pour afficher des entiers\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Prédictions')\n",
    "    plt.ylabel('Vraies valeurs')\n",
    "    plt.title(name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7YGtwymPfIo"
   },
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTXQI3wLQDVx"
   },
   "outputs": [],
   "source": [
    "model_mapping = {0:\"SVM\", 1:\"Logistic Regression\", 2:\"Random Forest\", 3:\"Gradient Boosting\", 4:\"k-Nearest Neighbors\", 5:\"Ensemble Learnings\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJZ9ob4rP94C"
   },
   "outputs": [],
   "source": [
    "# ENSEMBLE LEARNING\n",
    "def pos_max(t):\n",
    "    p = 0\n",
    "    for i in range(len(t)):\n",
    "        if t[i]>t[p]:\n",
    "            p = i\n",
    "    return p\n",
    "\n",
    "# Fonction qui prend les N_t (5) tableaux en entrées et renvoie un tableau\n",
    "# ensemble learning : e.l.\n",
    "def ensemble_learning(Preds):\n",
    "  Y_pred_el = []\n",
    "  N_t = len(Preds)\n",
    "  N = len(Preds[0])\n",
    "  for i in range(N):\n",
    "      total_par_genre = [0 for k in range(len(genre_mapping))]\n",
    "      for j in range(N_t):\n",
    "          total_par_genre[Preds[j][i]] += 1\n",
    "      # print(total_par_genre)\n",
    "      g = pos_max(total_par_genre)\n",
    "      Y_pred_el.append(g)\n",
    "  return Y_pred_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4B5Dr3ZQLMF"
   },
   "outputs": [],
   "source": [
    "#All Classifiers\n",
    "# couleur : \\033[1;3Om #30 à 37 avant le m\n",
    "\n",
    "# IMPORTS\n",
    "from time import sleep\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# FONCTION GENERALE --- UTILISABLE POUR PRÉDIRE LE GENRE DE N'IMPORTE QUELLE MUSIQUE\n",
    "def model_predictions(X_input):\n",
    "  scaler = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/scaler.pkl')\n",
    "  X_input = scaler.transform(X_input)\n",
    "  Preds = []\n",
    "  Y_pred_svm = model_svm.predict(X_input)\n",
    "  Preds.append(Y_pred_svm)\n",
    "  Y_pred_lr = model_lr.predict(X_input)\n",
    "  Preds.append(Y_pred_lr)\n",
    "  Y_pred_rf = model_rf.predict(X_input)\n",
    "  Preds.append(Y_pred_rf)\n",
    "  Y_pred_gbt = model_gbt.predict(X_input)\n",
    "  Preds.append(Y_pred_gbt)\n",
    "  Y_pred_knn = model_knn.predict(X_input)\n",
    "  Preds.append(Y_pred_knn)\n",
    "  Y_pred_el = ensemble_learning(Preds) #diff car e.l.\n",
    "  Preds.append(Y_pred_el)\n",
    "  return Preds\n",
    "\n",
    "# TRAINING\n",
    "model_svm = SVC(kernel='linear')\n",
    "model_svm.fit(X_train, Y_train)\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, Y_train)\n",
    "model_rf = RandomForestClassifier(n_estimators=103, random_state=42)\n",
    "model_rf.fit(X_train, Y_train)\n",
    "model_gbt = GradientBoostingClassifier()\n",
    "model_gbt.fit(X_train, Y_train)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train, Y_train)\n",
    "\n",
    "# POUR LE SET TEST\n",
    "resultats = False\n",
    "affichage = False\n",
    "comparaison = True\n",
    "if resultats:\n",
    "  Preds = model_predictions(X_test)\n",
    "  N_t = len(Preds)\n",
    "  N = len(Preds[0])\n",
    "  # ACCURACY\n",
    "  accuracy_svm = accuracy_score(Y_test, Preds[0])\n",
    "  print(f'\\033[1;31m Précision SVM : {accuracy_svm:.2%}')\n",
    "  accuracy_lr = accuracy_score(Y_test, Preds[1])\n",
    "  print(f'\\033[1;32m Précision LogisticRegression : {accuracy_lr:.2%}')\n",
    "  accuracy_rf = accuracy_score(Y_test, Preds[2])\n",
    "  print(f\"\\033[1;33m Précision RandomForest: {accuracy_rf:.2%}\")\n",
    "  accuracy_gbt = accuracy_score(Y_test, Preds[3])\n",
    "  print(f\"\\033[1;34m Précision GradientBoosting: {accuracy_gbt:.2%}\")\n",
    "  accuracy_knn = accuracy_score(Y_test, Preds[4])\n",
    "  print(f'\\033[1;35m Précision k-NearestNeighbours : {accuracy_knn:.2%}')\n",
    "  accuracy_el = accuracy_score(Y_test, Preds[N_t-1])\n",
    "  print(f'\\033[1;36m Précision EnsembleLearning : {accuracy_el:.2%}')\n",
    "\n",
    "  # PREDICTIONS\n",
    "  if affichage:\n",
    "    if not comparaison:\n",
    "      print(\"\\033[1;31m prédictions SVM : \" + str(Preds[0]))\n",
    "      print(\"\\033[1;32m prédictions LogisticRegression : \" + str(Preds[1]))\n",
    "      print(\"\\033[1;33m prédictions RandomForest : \" + str(Preds[2]))\n",
    "      print(\"\\033[1;34m prédictions GradientBoosting : \" + str(Preds[3]))\n",
    "      print(\"\\033[1;35m prédictions K-Nearest Neighbors : \" + str(Preds[4]))\n",
    "      print(\"\\033[1;36m prédictions EnsembleLearning : \" + str(Preds[N_t-1]))\n",
    "    else:\n",
    "      print(\"\\033[1;30m Toutes les prédictions : \")\n",
    "      for i in range(N):\n",
    "        for j in range(N_t):\n",
    "          string = ''\n",
    "          string += f'\\033[1;{31+j}m'\n",
    "          string += f'{Preds[j][i]} '\n",
    "          print(string, end='')\n",
    "        print(f'\\033[1;30m \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkrt5-UMDpTT"
   },
   "outputs": [],
   "source": [
    "# -- on a besoin de extract features sans ajouter à X et Y\n",
    "\n",
    "def array_features(files, duration=30, sr=22050):\n",
    "  N_f = len(files)\n",
    "  X_features = []\n",
    "  Y_genres = []\n",
    "  def stats(feature):\n",
    "      return list(map(float, np.mean(feature, axis=1))) + list(map(float, np.std(feature, axis=1)))\n",
    "  print('Extracting features :', end='')\n",
    "  for i in range(N_f):\n",
    "    file_path = files[i]\n",
    "    file_name = os.path.basename(file_path).replace('.mp3','.png').replace('.wav','.png')\n",
    "    y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "    # Extraction des features\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    zero_crossing = librosa.feature.zero_crossing_rate(y=y)\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    # Construction du vecteur de features\n",
    "    features = []\n",
    "    for f in [mfcc, rms, spectral_centroid, bandwidth, contrast, flatness, rolloff, tonnetz, zero_crossing]:\n",
    "        features.extend(stats(f))\n",
    "    features.append(float(tempo))\n",
    "    X_features.append(features)\n",
    "    genre = (os.path.splitext(os.path.basename(file_path))[0]).split('.')[0]\n",
    "    Y_genres.append(genre)\n",
    "    print(f'{i+1}✓', end='')\n",
    "  print('')\n",
    "  return X_features, Y_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HE1t7qkx2PlL"
   },
   "outputs": [],
   "source": [
    "# SAMUEL -- on a besoin de extract features sans ajouter à X et Y\n",
    "\n",
    "def array_features(files, duration=30, sr=22050):\n",
    "  N_f = len(files)\n",
    "  X_features = []\n",
    "  Y_genres = []\n",
    "  def stats(feature):\n",
    "      return list(map(float, np.mean(feature, axis=1))) + list(map(float, np.std(feature, axis=1)))\n",
    "  print('Extracting features :', end='')\n",
    "  for i in range(N_f):\n",
    "    file_path = files[i]\n",
    "    file_name = os.path.basename(file_path).replace('.mp3','.png').replace('.wav','.png')\n",
    "    y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "    # Extraction des features\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    zero_crossing = librosa.feature.zero_crossing_rate(y=y)\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    # Construction du vecteur de features\n",
    "    features = []\n",
    "    for f in [mfcc, rms, spectral_centroid, bandwidth, contrast, flatness, rolloff, tonnetz, zero_crossing]:\n",
    "        features.extend(stats(f))\n",
    "    features.append(float(tempo))\n",
    "    X_features.append(features)\n",
    "    genre = (os.path.splitext(os.path.basename(file_path))[0]).split('.')[0]\n",
    "    Y_genres.append(genre)\n",
    "    print(f'{i+1}✓', end='')\n",
    "  print('')\n",
    "  return X_features, Y_genres\n",
    "\n",
    "# Juste le genre svp\n",
    "\n",
    "def extract_known_genre(files, duration=30, sr=22050):\n",
    "  N_f = len(files)\n",
    "  Y_genres = []\n",
    "  for i in range(N_f):\n",
    "    file_path = files[i]\n",
    "    genre = (os.path.splitext(os.path.basename(file_path))[0]).split('.')[0]\n",
    "    Y_genres.append(genre)\n",
    "  return Y_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPojf_w22ZG0"
   },
   "outputs": [],
   "source": [
    "# FINAL EL FOR PREDICTION\n",
    "# pour le moment tqt\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "F = audio_files #np.random.choice(audio_files, 100, replace=False) # ou autre Files array\n",
    "W = extract_known_genre(F)\n",
    "\n",
    "df2 = pd.DataFrame(F)\n",
    "df2['genre'] = W\n",
    "df2['genre'] = df2['genre'].astype('category')\n",
    "genre_mapping = dict(enumerate(df2['genre'].cat.categories))\n",
    "df2['genre'] = df2['genre'].astype('category').cat.codes\n",
    "F_train, F_test, W_train, W_test = train_test_split(df2.drop(columns=['genre'],), df2['genre'], test_size=0.2, random_state = 42,stratify = W)\n",
    "F_train = F_train.squeeze().tolist()\n",
    "F_test = F_test.squeeze().tolist()\n",
    "W_train = W_train.tolist()\n",
    "W_test = W_test.tolist()\n",
    "F_meta_train, F_meta_test, W_meta_train, W_meta_test = train_test_split(F_test, W_test, test_size=0.2, random_state=42, stratify=W_test)\n",
    "#save_dir = '/content/drive/MyDrive/Artishow/Modèle/ML' ça s'était pour logistic regression\n",
    "#joblib.dump(model, os.path.join(save_dir, \"Logi.pkl\")) ça s'était pour logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7GBIV0SzZom",
    "outputId": "57ca11bc-75ae-4043-c671-d43d6f0768be"
   },
   "outputs": [],
   "source": [
    "# essais ensemble learning 2\n",
    "# partie cnn\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras.preprocessing.image as image\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "model_cnn = tf.keras.models.load_model(\"/content/drive/MyDrive/Artishow/Modèle/IA/vgg16_genre_classification.h5\")\n",
    "save_dir = \"/content/drive/MyDrive/Artishow/spectrogramStorage/MusiquePerso\"\n",
    "\n",
    "def audio_to_mel_spec(audio_path, save_dir, sr=22050, n_mels=128, hop_length=512):\n",
    "    y, sr = librosa.load(audio_path, sr=sr, duration=30)\n",
    "    melspec = librosa.feature.melspectrogram(y=y, sr=sr,n_mels=n_mels, hop_length=hop_length)\n",
    "    melspec_db = librosa.power_to_db(melspec, ref=np.max)\n",
    "    # Plot & save spectrogram\n",
    "    plt.figure(figsize=(4.32, 2.88), dpi=100)  # image 224x224 pixels\n",
    "    #librosa.display.specshow(melspec_db)  # ou 'inferno'\n",
    "    plt.imshow(melspec_db, aspect='auto', origin='lower', cmap='magma', vmin=-42, vmax=0)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    # Generate unique filename\n",
    "    file_name = os.path.basename(audio_path).replace('.mp3','.png').replace('.wav','.png')\n",
    "    save_path = os.path.join(save_dir, file_name)\n",
    "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close() # Close the plot to prevent it from displaying\n",
    "    return save_path\n",
    "\n",
    "def load_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.  # Si tu as utilisé rescale=1./255\n",
    "    return img_array\n",
    "\n",
    "def pre_process_cnn(files):\n",
    "  im_arrays = []\n",
    "  spec_paths = []\n",
    "  for f in files:\n",
    "    spec_path = audio_to_mel_spec(f, save_dir)\n",
    "    img_array = load_image(spec_path)\n",
    "    im_arrays.append(img_array)\n",
    "    spec_paths.append(spec_path) # Store the path to clean up later\n",
    "  return np.vstack(im_arrays), spec_paths # Stack the images to a single numpy array\n",
    "\n",
    "# partie machine learning\n",
    "from time import sleep\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# TRAINING\n",
    "# à voir si besoin de réentraîner\n",
    "model_svm = SVC(kernel='linear', probability=True)\n",
    "model_svm.fit(X_train, Y_train)\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, Y_train)\n",
    "model_rf = RandomForestClassifier(n_estimators=103, random_state=42)\n",
    "model_rf.fit(X_train, Y_train)\n",
    "model_gbt = GradientBoostingClassifier()\n",
    "model_gbt.fit(X_train, Y_train)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train, Y_train)\n",
    "\n",
    "# general\n",
    "def model_probas(files): #CNN !!!!!!!\n",
    "  scaler = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/scaler.pkl')\n",
    "  X_features, _ = array_features(files) # le 2e c'est les genres\n",
    "  X_input = scaler.transform(X_features)\n",
    "  Y_probas_svm = model_svm.predict_proba(X_input)\n",
    "  Y_probas_lr = model_lr.predict_proba(X_input)\n",
    "  Y_probas_rf = model_rf.predict_proba(X_input)\n",
    "  Y_probas_gbt = model_gbt.predict_proba(X_input)\n",
    "  Y_probas_knn = model_knn.predict_proba(X_input)\n",
    "  im_arrays, spec_paths = pre_process_cnn(files)\n",
    "  Y_probas_cnn = model_cnn.predict(im_arrays)\n",
    "  Z_input = []\n",
    "  for i in range(len(files)): # Iterate through the number of files\n",
    "    Z_input.append([*Y_probas_svm[i], *Y_probas_lr[i], *Y_probas_rf[i], *Y_probas_gbt[i], *Y_probas_knn[i], *Y_probas_cnn[i]])\n",
    "  # Clean up generated spectrogram files #ça c'est l'ia google mais bon jvais laisser mdr\n",
    "  for spec_path in spec_paths:\n",
    "      os.remove(spec_path)\n",
    "  return Z_input\n",
    "\n",
    "#essai\n",
    "#files1 = audio_files[:3]\n",
    "#files2 = [\"/content/drive/MyDrive/Artishow/Musique perso/Dua Lipa - Houdini.mp3\"]\n",
    "#Z = model_probas(files1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0CB-2DHC-X5"
   },
   "outputs": [],
   "source": [
    "# ENSEMBLE LEARNING\n",
    "def pos2_max(t):\n",
    "  p1 = 0\n",
    "  p2 = 0\n",
    "  for i in range(len(t)):\n",
    "    if t[i]>t[p1]:\n",
    "      p2 = p1\n",
    "      p1 = i\n",
    "    elif t[i]>t[p2]:\n",
    "      p2 = i\n",
    "  return (p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJRKqva6zcyx",
    "outputId": "28e9abf4-47a0-419c-b46c-40611ad49194"
   },
   "outputs": [],
   "source": [
    "# META MODEL TRAINING\n",
    "Z_meta_train = model_probas(F_meta_train)\n",
    "Z_meta_test = model_probas(F_meta_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Z_meta_train = scaler.fit_transform(Z_meta_train)\n",
    "Z_meta_test = scaler.transform(Z_meta_test)\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(Z_meta_train, W_meta_train)\n",
    "#W_meta_pred_test = meta_model.predict(Z_meta_test)\n",
    "#accuracy = accuracy_score(W_meta_pred_test, W_meta_test)\n",
    "#print(f'Précision du modèle : {accuracy:.2%}')\n",
    "#W_2rep = meta_model_predictions(Z_meta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3zMF18yIHBr"
   },
   "outputs": [],
   "source": [
    "def meta_model_predictions(Z_input):\n",
    "  Ws = meta_model.predict_proba(Z_input)\n",
    "  W_2rep = [pos2_max(v) for v in Ws]\n",
    "  return W_2rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbHoQ2Y-7NeK",
    "outputId": "e11a6303-2068-4ddc-bad7-2835ba081e54"
   },
   "outputs": [],
   "source": [
    "print(F_meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJfLlezW5Yqd",
    "outputId": "34c05d41-9a2f-4021-e538-74a2f3e5ab31"
   },
   "outputs": [],
   "source": [
    "print(audio_files[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOgz_9v2M6Yc"
   },
   "source": [
    "# PHASE 2 : Playlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6o_BqblzNXvv"
   },
   "source": [
    "## Triage d'un tableau par genre - sorting a table by genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzO3rGqSN6Bo"
   },
   "outputs": [],
   "source": [
    "# Algorithme qui prend plein de musiques et en détermine le genre\n",
    "from tabulate import tabulate\n",
    "import random\n",
    "\n",
    "# Récupérer des files -- à changer avec un dossier\n",
    "subset = random.sample(audio_files, 10)\n",
    "X_subset, Y_genres = array_features(subset)\n",
    "X_names = [os.path.basename(file).replace('.mp3','').replace('.wav','') for file in subset] #file_name for file in subset\n",
    "\n",
    "Songs = list(map(lambda x,y : (x,y), X_names, Y_genres))\n",
    "affiche_tab_t_g(Songs, statut=\"connu\")\n",
    "\n",
    "tab = model_predictions(X_subset)\n",
    "for i in range(len(tab)):\n",
    "  print(model_mapping[i])\n",
    "  Songs = list(map(lambda x, y: (x,genre_mapping[y]), X_names, tab[i]))\n",
    "  affiche_tab_t_g(Songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbHo6gXkN06S"
   },
   "outputs": [],
   "source": [
    "# Algorithme qui affiche un tableau (titre, genre) trié par genre\n",
    "from tabulate import tabulate\n",
    "import random\n",
    "\n",
    "# L'algo\n",
    "def affiche_tab_t_g(couples, statut=\"prédit\"):\n",
    "  couples.sort(key=lambda tuple: tuple[1]) #sort by second parameter (ordre alphabétique)\n",
    "  print(tabulate(couples, headers=['Title', f'Genre ({statut})'], tablefmt=\"rounded_grid\"))\n",
    "\n",
    "# Exemple\n",
    "# Récupérer des couples pour un exemple\n",
    "subset = random.sample(audio_files, 100)\n",
    "Songs = []\n",
    "for i in range(10):\n",
    "  file_path = subset[i]\n",
    "  genre = (os.path.splitext(os.path.basename(file_path))[0]).split('.')[0]\n",
    "  file_name = os.path.basename(file_path).replace('.mp3','.png').replace('.wav','.png')\n",
    "  Songs.append((file_name, genre))\n",
    "affiche_tab_t_g(Songs, statut=\"connu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPLBqgu7znaO"
   },
   "source": [
    "## Imports Deezer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqbxwq2AzqS0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from google.colab import drive\n",
    "\n",
    "# Monter Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Chemin de base où les fichiers seront stockés\n",
    "base_path = '/content/drive/My Drive/Artishow/Deezer'\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# Genres musicaux à traiter\n",
    "genres = ['jazz', 'country', 'pop', 'reggae', 'blues',\n",
    "          'hiphop', 'classical', 'disco', 'metal', 'rock']\n",
    "\n",
    "# Fonction pour rechercher les playlists liées à un genre\n",
    "def get_playlists_for_genre(genre, limit=5):\n",
    "    url = f'https://api.deezer.com/search/playlist?q={genre}'\n",
    "    response = requests.get(url).json()\n",
    "    return response.get('data', [])[:limit]\n",
    "\n",
    "# Fonction pour extraire les morceaux d'une playlist\n",
    "def get_tracks_from_playlist(playlist_id):\n",
    "    url = f'https://api.deezer.com/playlist/{playlist_id}'\n",
    "    response = requests.get(url).json()\n",
    "    tracks = response.get('tracks', {}).get('data', [])\n",
    "    results = []\n",
    "    for track in tracks:\n",
    "        results.append({\n",
    "            'track_id': track['id'],\n",
    "            'title': track['title'],\n",
    "            'artist': track['artist']['name'],\n",
    "            'rank': track['rank'],\n",
    "            'preview': track['preview']\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Boucle principale sur chaque genre\n",
    "for genre in genres:\n",
    "    print(f\"\\n Traitement du genre : {genre}\")\n",
    "    all_tracks = []\n",
    "\n",
    "    # Créer le dossier pour ce genre\n",
    "    genre_folder = os.path.join(base_path, genre)\n",
    "    os.makedirs(genre_folder, exist_ok=True)\n",
    "\n",
    "    # Récupérer les playlists populaires du genre\n",
    "    playlists = get_playlists_for_genre(genre, limit=5)\n",
    "    if not playlists:\n",
    "        print(f\"Aucune playlist trouvée pour {genre}\")\n",
    "        continue\n",
    "\n",
    "    # Récupérer les morceaux de chaque playlist\n",
    "    for playlist in playlists:\n",
    "        playlist_id = playlist['id']\n",
    "        try:\n",
    "            tracks = get_tracks_from_playlist(playlist_id)\n",
    "            all_tracks.extend(tracks)\n",
    "        except:\n",
    "            print(f\"Erreur lors du traitement de la playlist {playlist_id}\")\n",
    "        time.sleep(0.5)  # Respecter un petit délai pour l'API\n",
    "\n",
    "    if not all_tracks:\n",
    "        print(f\" Aucun morceau récupéré pour {genre}\")\n",
    "        continue\n",
    "\n",
    "    # Nettoyage : enlever les doublons, trier par popularité (rank décroissant), garder les 100 premiers\n",
    "    df = pd.DataFrame(all_tracks)\n",
    "    df.drop_duplicates(subset='track_id', inplace=True)\n",
    "    df.sort_values(by='rank', ascending=False, inplace=True)\n",
    "    df_top100 = df.head(100)\n",
    "\n",
    "    # Sauvegarder la liste CSV (utile pour audit)\n",
    "    csv_path = os.path.join(genre_folder, f'{genre}_top100.csv')\n",
    "    df_top100.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Télécharger les previews MP3 dans le dossier du genre\n",
    "    print(f\"Téléchargement des previews pour {genre}\")\n",
    "    for _, row in df_top100.iterrows():\n",
    "        track_id = row['track_id']\n",
    "        title = row['title']\n",
    "        preview_url = row['preview']\n",
    "\n",
    "        # Vérifier que le lien est bien un lien valide\n",
    "        if not isinstance(preview_url, str) or not preview_url.startswith(\"http\"):\n",
    "            continue\n",
    "\n",
    "        # Construire un nom de fichier propre\n",
    "        safe_title = title[:30].replace('/', '_').replace('\\\\', '_')\n",
    "        filename = f\"{track_id}_{safe_title}.mp3\"\n",
    "        filepath = os.path.join(genre_folder, filename)\n",
    "\n",
    "        # Télécharger uniquement si pas déjà présent\n",
    "        if os.path.exists(filepath):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            r = requests.get(preview_url)\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            print(f\"{filename}\")\n",
    "        except:\n",
    "            print(f\"Échec pour {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f_Cq-DDEeii",
    "outputId": "c1fce6fd-4156-472c-8d56-144aed8a5d0b"
   },
   "outputs": [],
   "source": [
    "files2 = filepaths = ['/content/drive/My Drive/Artishow/Deezer/pop/3242688291_NINAO.mp3']\n",
    "Ze = model_probas(files2)\n",
    "Ws = meta_model_predictions(Ze)\n",
    "print(files2)\n",
    "print(Ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E_bEqthORCH"
   },
   "source": [
    "## Génération de playlist - Playlist Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSouVv3e6fSc"
   },
   "source": [
    "### Génération de playlist à partir d'un mood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0Okv--u6pt0"
   },
   "source": [
    "### Approche 1 : simpliste avec des boutons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_fMUu7d6pGL"
   },
   "outputs": [],
   "source": [
    "moods = ['happy', 'relaxing', 'dark', 'epic', 'dream', 'sad', 'motivational', 'deep', 'romantic', 'emotional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dsl16YSA7IC1"
   },
   "outputs": [],
   "source": [
    "def playlist_generator_mood_1(mood):\n",
    "  # Filtrer selon le mood/genre\n",
    "    filtered_df = df_audio[df_audio['mood'].apply(lambda moods: mood in moods)]\n",
    "\n",
    "    # Vérification\n",
    "    if filtered_df.empty:\n",
    "        print(f\"Aucun morceau trouvé pour le mood : {mood}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Tirage aléatoire de n morceaux (ou moins si pas assez)\n",
    "    playlist = filtered_df.sample(n=min(15, len(filtered_df)), random_state=42)\n",
    "\n",
    "    return playlist[['filename', 'filepath']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "g0zTCyjF7LNq",
    "outputId": "81295fde-05a8-473c-a0eb-6c440f03b8bf"
   },
   "outputs": [],
   "source": [
    "# Action à exécuter lorsqu'on clique sur un bouton\n",
    "def on_button_click(b):\n",
    "    mood_clicked = b.description.lower()\n",
    "    clear_output(wait=True)\n",
    "    display(widgets.HBox(buttons), output)\n",
    "    with output:\n",
    "        print(f\"🎧 Playlist pour le mood : {mood_clicked}\")\n",
    "        playlist = generate_playlist(mood_clicked, df_audio_features)\n",
    "        display(playlist)\n",
    "\n",
    "# Associer l'événement à chaque bouton\n",
    "for button in buttons:\n",
    "    button.on_click(on_button_click)\n",
    "\n",
    "# Afficher l'interface\n",
    "display(widgets.HBox(buttons), output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLSjtVME7PcW"
   },
   "source": [
    "## Approche 2 : A partir d'une phrase - Generate from a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqB3UhcB7UqL"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKp4QY857ZG2"
   },
   "outputs": [],
   "source": [
    "# Commande pour supprimer récursivement (-r) et forcer (-f) le dossier du cache\n",
    "# Le \"!\" au début permet d'exécuter une commande système dans Colab\n",
    "!rm -rf ~/.cache/huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350,
     "referenced_widgets": [
      "61543ae19bed4950ad236045ef26dab5",
      "fd33a7a5c4d94e9caad4d9d5d91df7cf",
      "285fd2701ed24565a54bb6c036680eb7",
      "b41aa8078ca042eda36b7c913bc78aea",
      "e3f8d444fb584972a388681b1bb467c1",
      "cabd60f6c32f49a4b49399d5eff3e6fb",
      "5019cdcd8fa24f5b80d2484cb677bbef",
      "44e35c10b5e748b18ac6780b3039b535",
      "aadf4552eee5433ea9b0b1b409e85828",
      "b6d182741c834e17b7f3f4e27ac1ee95",
      "494ed3e1e5c14c8d93aa56d3cd0a16a0",
      "13e98267e0344a87afb1f9c1a5d067f9",
      "baadda8d2f4543579398021cfe358d0b",
      "4e1793bed1364734b6fea7d0f610e993",
      "9836d85f6626473c8877845936fc3e3f",
      "7959be900bf8474fb33ac72d1c362351",
      "43674a519dfc41728683b82c21c8a929",
      "b1e84a8e12884b20a99c4f4579082f5c",
      "793d55663e6a4f9ab0d84aeb59deb725",
      "bb03c49ce9144528a470ff348e0b5fa6",
      "753d557450134de5ad74b16d7706475a",
      "452d13c55d59402cb4b8c4cbc6119e56",
      "33ba53fa3029410fa8da2d0face4a25a",
      "29cdbd4237a34fcea895282213af951b",
      "9c8337837ce745eda56c33a7188aa676",
      "7cdf659c4c1745308c80167881f312a8",
      "ffd749db2bcc4c0cbb689d2ddf3d2c56",
      "38d19e6a068d439dbf0353f0366a36ff",
      "3f2c2aa0419349ea9aa6d5fe96fedfe4",
      "7080fd142ac84918940002626d30bf7f",
      "8301f54145c44076b75d1098da6ee7c1",
      "195f34cd6d924a7fa9079bf20631a0e3",
      "ee0ee5bec89d4fddb9ccd573102bfd9e",
      "41de360bd02e42f29b96a283e36e9827",
      "cb15227191174e70983f170916b00a06",
      "17e99f8a87a94ad4bd4cd0162e1aa3d5",
      "e56f9214216041019e3fb0b42d5ed507",
      "eff3907f4be94ebeb112e1eb3fa59843",
      "99e7a21185cf4cbca933b82446310a5c",
      "b09e496afa7b401c8b91d5cb48c4f952",
      "085ee6d8e6f44f0393687dafa5dcca17",
      "7ef68652987b42909e7b74e016bb9433",
      "3f0e44797fad4314b37d69f379937549",
      "7eef4a75cbbd4e7497df798c1d38c9a9",
      "7b57700e13544d6d8b2766e73a7865d0",
      "c00e7301998f4c82b5eeddff985b52f7",
      "8bdfa7a6f6f54fca986be8abd76a45f3",
      "16731528164248a092cc5a5bf9e7eae4",
      "1ac09453be564764a29a16afa4270e10",
      "29d8021b4f0943e5a71339f4fb4f1ba4",
      "f07e9646edeb441b87ec6f9bd219a95b",
      "bda1f3a7be6f4fdaae69204fae7e67b1",
      "5035b13402874eadbd6e4374fe4883d3",
      "a2abf958e55b4c6795f461bd1a7c814e",
      "d06eb7e3081043cd9748b41b33716390",
      "28904d5a5c334a95b7f99be2b8a804bf",
      "d550a1e9ede7479d82426eac5bf87c76",
      "b795dc71027d4987b083ef041935991b",
      "c125ca5955374bb5b2080257c259ad2f",
      "73a5745fcc7043d8a0d6ca2a5f3d68ed",
      "09a3594dc8ed447281049404fda0f19f",
      "ece694ec206f4a87b2ee220ec12e2544",
      "8cb2c486f44a4d67b56bd532fc008ff0",
      "e7e9e7190ea640c09e6f86ab699322b1",
      "762442bb9595481d84a6fb112f73db90",
      "954e760095ed4267af8533e3cc1d29fd"
     ]
    },
    "id": "JzzkARM_7c47",
    "outputId": "d53aa58e-7fe1-4a18-bad1-1a1abeb7b191"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")  ### Modèle déjà entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLURmW507fpR"
   },
   "outputs": [],
   "source": [
    "phrase_utilisateur = \"I'm doing an incredible battle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CzEPOGEz7n22",
    "outputId": "b76b8cd7-6be9-41b6-89ad-c1254e670e3b"
   },
   "outputs": [],
   "source": [
    "### On lance la classification\n",
    "\n",
    "resultat = classifier(phrase_utilisateur, moods)\n",
    "print(f\"Phrase à analyser : '{resultat['sequence']}'\")\n",
    "print(\"\\nRésultats du classement des moods :\")\n",
    "# Le résultat est une liste de labels triés du plus probable au moins probable.\n",
    "for label, score in zip(resultat['labels'], resultat['scores']):\n",
    "    print(f\"- Mood : {label}, Score : {score:.2%}\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKOX82ZQ7qa9"
   },
   "outputs": [],
   "source": [
    "def generator_playlist_mood():\n",
    "  phrase_utilisateur = str(input(\"Quel est votre mood actuel ? \"))\n",
    "  resultats = classifier(phrase_utilisateur, moods)\n",
    "  mood = resultats['labels'][0]\n",
    "  playlist = playlist_generator_mood_1(mood)\n",
    "  if len(playlist) < 5:\n",
    "    playlist = pd.concat([playlist, playlist_generator_mood_1(resultats['labels'][1])])\n",
    "  return playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "cKH9XizC7vJw",
    "outputId": "9264fdb1-cf45-416d-ba9b-52b3634f612b"
   },
   "outputs": [],
   "source": [
    "generator_playlist_mood()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaG7yQf77zvS"
   },
   "source": [
    "## Génération à partir d'une musique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8klyu0w72u9"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "API_URL = \"https://api.deezer.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXxZh4PR75K2"
   },
   "outputs": [],
   "source": [
    "### Recherche de la musique\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "API_URL = \"https://api.deezer.com\"\n",
    "\n",
    "\n",
    "# Fonction pour chercher une chanson et retourner son ID et son titre\n",
    "def search_track(song_name: str):\n",
    "    print(f\"1. Recherche de la chanson : '{song_name}'...\")\n",
    "\n",
    "    response = requests.get(f\"{API_URL}/search/track\", params={\"q\": song_name})\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Erreur lors de la recherche.\")\n",
    "        return None\n",
    "\n",
    "    data = response.json()\n",
    "    if not data.get('data'):\n",
    "        print(\"Aucune chanson trouvée.\")\n",
    "        return None\n",
    "\n",
    "    # On prend le premier résultat, qui est généralement le plus pertinent\n",
    "    first_result = data['data'][0]\n",
    "    track_id = first_result['id']\n",
    "    track_title = first_result['title']\n",
    "    artist_name = first_result['artist']['name']\n",
    "    url = first_result['link']\n",
    "\n",
    "    print(f\"   -> Chanson trouvée : '{track_title}' par {artist_name} (ID: {track_id})\")\n",
    "    return {\"id\": track_id, \"title\": track_title, 'url' : url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoxWvR8bndlX",
    "outputId": "a09f4f40-b4e5-4980-85c9-dbadf90510af"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Extensions audio reconnues\n",
    "AUDIO_EXTENSIONS = ('.mp3', '.wav', '.flac', '.ogg', '.aac', '.m4a')\n",
    "\n",
    "# Genres disponibles dans deezer\n",
    "genres = [\n",
    "    \"rock\", \"reggae\", \"pop\", \"metal\", \"jazz\",\n",
    "    \"hiphop\", \"disco\", \"country\", \"classical\", \"blues\"\n",
    "]\n",
    "\n",
    "# Définir le chemin vers ton dossier deezer dans Drive\n",
    "base_path = '/content/drive/MyDrive/Artishow/Deezer'\n",
    "\n",
    "# Fonction de collecte\n",
    "def collect_audio_files_info(base_path):\n",
    "    data = []\n",
    "    dict = {}\n",
    "\n",
    "    for genre in genres:\n",
    "        genre_folder = os.path.join(base_path, genre)\n",
    "        if not os.path.exists(genre_folder):\n",
    "            print(f\"[Avertissement] Dossier introuvable : {genre_folder}\")\n",
    "            continue\n",
    "\n",
    "        for root, _, files in os.walk(genre_folder):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(AUDIO_EXTENSIONS):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    data.append({\n",
    "                        \"filename\": file,\n",
    "                        \"filepath\": full_path,\n",
    "                        \"genre\": genre\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_audio = collect_audio_files_info(base_path)\n",
    "\n",
    "audio_files_2 = df_audio['filepath']\n",
    "audio_files_2 = audio_files_2.tolist()\n",
    "\n",
    "print(audio_files_2[:5])\n",
    "print(df_audio.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ma23xp085Byc"
   },
   "outputs": [],
   "source": [
    "def playlist_generator_music(song_name: str):\n",
    "  id = search_track(song_name)['id']\n",
    "  genre = genre_decoding(p_vote_maj(Votes_of(models_Genres_probas_of(audio_files[:2], \"paths\"))))\n",
    "  mood = f_mood_tristan(search_track(id))\n",
    "  filtered_df = df_audio[\n",
    "    df_audio['mood'].apply(lambda moods: mood in moods) &\n",
    "    (df_audio['genre'] == genre[0])\n",
    "]\n",
    "  if filtered_df.empty:\n",
    "    filtered_df = df_audio[\n",
    "      df_audio['genre'] == genre[0]\n",
    "  ]\n",
    "    return filtered_df.sample(n=min(15, len(filtered_df)), random_state=42)\n",
    " # Tirage aléatoire de n morceaux (ou moins si pas assez)\n",
    "  playlist = filtered_df.sample(n=min(15, len(filtered_df)), random_state=42)\n",
    "  return playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVRrGYpn78Op"
   },
   "outputs": [],
   "source": [
    "def playlist_generator_music(song_name: str):\n",
    "    id = search_track(song_name)['id']\n",
    "    genre = genre_decoding(p_vote_maj(Votes_of(models_Genres_probas_of(audio_files, \"paths\"))))\n",
    "    mood = f_mood_tristan(search_track(id))\n",
    "\n",
    "    filtered_df = df_audio[\n",
    "    (df_audio['mood'] == mood) &\n",
    "    (df_audio['genre'] == genre[0])\n",
    "]\n",
    "\n",
    "\n",
    "    if len(filtered_df) < 5:\n",
    "        base_df = df_audio.copy()\n",
    "\n",
    "        already_selected = base_df.index\n",
    "        genre_df = df_audio[\n",
    "            (df_audio['genre'] == genre[0]) &\n",
    "            (~df_audio.index.isin(already_selected))\n",
    "        ]\n",
    "\n",
    "\n",
    "        to_add = min(8 - len(base_df), len(genre_df))\n",
    "        additional_df = genre_df.sample(n=to_add, random_state=42)\n",
    "\n",
    "        final_df = pd.concat([base_df, additional_df])\n",
    "        final_df = final_df.sample(n=min(8, len(final_df)), random_state=42)\n",
    "    else:\n",
    "\n",
    "        final_df = filtered_df.sample(n=min(15, len(filtered_df)), random_state=42)\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "ju-7bd-iLdVZ",
    "outputId": "5fbb0224-786e-4369-926d-977df8e4503f"
   },
   "outputs": [],
   "source": [
    "playlist_generator_music(\"7 rings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Me9KiLhR8iiD",
    "outputId": "b1791134-e8ab-49f3-d823-17f0747a30fc"
   },
   "outputs": [],
   "source": [
    "df_audio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "935Kvvrp8HSI"
   },
   "source": [
    "## Génération de playlist à partir d'un audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvxCLqR38KT-"
   },
   "outputs": [],
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dVndH828PxZ"
   },
   "outputs": [],
   "source": [
    "# Importations nécessaires\n",
    "from IPython.display import HTML, Audio, display\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read, write\n",
    "import io\n",
    "import ffmpeg # Pour la conversion de format\n",
    "\n",
    "# --- LE COEUR DE LA FONCTION : LE TEMPLATE JAVASCRIPT ---\n",
    "# Ce code n'est pas exécuté par Python, mais sera envoyé au navigateur.\n",
    "AUDIO_HTML = \"\"\"\n",
    "<script>\n",
    "var my_div = document.createElement(\"DIV\");\n",
    "var my_p = document.createElement(\"P\");\n",
    "var my_btn = document.createElement(\"BUTTON\");\n",
    "var my_progress = document.createElement(\"PROGRESS\");\n",
    "var my_span = document.createElement(\"SPAN\");\n",
    "\n",
    "// Configuration de l'interface utilisateur\n",
    "my_p.innerHTML = \"Appuyez sur le bouton pour démarrer l'enregistrement :\";\n",
    "my_btn.innerHTML = \"Enregistrer (30s)\";\n",
    "my_progress.value = 0;\n",
    "my_progress.max = 100;\n",
    "my_span.innerHTML = \" 0%\";\n",
    "\n",
    "// Ajout des éléments à la page\n",
    "document.body.appendChild(my_div);\n",
    "my_div.appendChild(my_p);\n",
    "my_div.appendChild(my_btn);\n",
    "my_div.appendChild(my_progress);\n",
    "my_div.appendChild(my_span);\n",
    "\n",
    "var recorder;\n",
    "var interval;\n",
    "var startTime;\n",
    "const DURATION = 30000; // Durée en millisecondes (30s)\n",
    "\n",
    "// Fonction pour mettre à jour la barre de progression\n",
    "function updateProgress() {\n",
    "    let elapsedTime = new Date() - startTime;\n",
    "    let progress = (elapsedTime / DURATION) * 100;\n",
    "    my_progress.value = Math.min(progress, 100);\n",
    "    my_span.innerHTML = ` ${Math.round(Math.min(progress, 100))}%`;\n",
    "}\n",
    "\n",
    "// Fonction pour démarrer l'enregistrement\n",
    "function startRecording() {\n",
    "    my_btn.innerHTML = \"En cours... Cliquez pour arrêter\";\n",
    "    my_btn.onclick = stopRecording; // Le bouton sert maintenant à arrêter\n",
    "\n",
    "    // Demande l'accès au microphone\n",
    "    navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {\n",
    "        recorder = new MediaRecorder(stream);\n",
    "        recorder.start();\n",
    "        startTime = new Date();\n",
    "\n",
    "        // Mettre à jour la barre de progression toutes les 100ms\n",
    "        interval = setInterval(updateProgress, 100);\n",
    "\n",
    "        // Récupérer les données audio\n",
    "        let chunks = [];\n",
    "        recorder.ondataavailable = e => chunks.push(e.data);\n",
    "\n",
    "        // Quand l'enregistrement s'arrête (manuellement ou à la fin)\n",
    "        recorder.onstop = e => {\n",
    "            let blob = new Blob(chunks, { 'type' : 'audio/webm; codecs=opus' });\n",
    "            let reader = new FileReader();\n",
    "            reader.onload = () => {\n",
    "                // Retourner l'audio à Python\n",
    "                var b64 = reader.result.split(',')[1];\n",
    "                google.colab.kernel.invokeFunction('notebook.save_audio', [b64], {});\n",
    "            };\n",
    "            reader.readAsDataURL(blob);\n",
    "        };\n",
    "\n",
    "        // Arrêter automatiquement après DURATION\n",
    "        setTimeout(stopRecording, DURATION);\n",
    "    });\n",
    "}\n",
    "\n",
    "// Fonction pour arrêter l'enregistrement\n",
    "function stopRecording() {\n",
    "    if (recorder && recorder.state === \"recording\") {\n",
    "        recorder.stop();\n",
    "        clearInterval(interval);\n",
    "        my_btn.innerHTML = \"Terminé !\";\n",
    "        my_btn.disabled = true;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Lier la fonction de démarrage au clic initial\n",
    "my_btn.onclick = startRecording;\n",
    "\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "# --- LA FONCTION PYTHON QUI ORCHESTRE LE TOUT ---\n",
    "def record_audio(filename=\"enregistrement.wav\"):\n",
    "    \"\"\"\n",
    "    Lance une interface d'enregistrement audio dans Colab pour 30s.\n",
    "    L'enregistrement peut être arrêté manuellement.\n",
    "    Sauvegarde l'audio dans un fichier WAV.\n",
    "    \"\"\"\n",
    "\n",
    "    # Étape 1: Définir une fonction que JavaScript pourra appeler pour renvoyer l'audio\n",
    "    audio_data = None\n",
    "    def save_audio(b64_data):\n",
    "        nonlocal audio_data\n",
    "        audio_data = b64decode(b64_data)\n",
    "\n",
    "    output.register_callback('notebook.save_audio', save_audio)\n",
    "\n",
    "    # Étape 2: Afficher l'interface HTML/JS\n",
    "    print(\"Préparation de l'interface d'enregistrement...\")\n",
    "    display(HTML(AUDIO_HTML))\n",
    "\n",
    "    # Étape 3: Attendre que JavaScript renvoie les données\n",
    "    # Cette boucle attend que la variable audio_data soit remplie par le callback\n",
    "    while audio_data is None:\n",
    "        pass\n",
    "\n",
    "    print(\"\\nEnregistrement terminé. Conversion et sauvegarde en cours...\")\n",
    "\n",
    "    # Étape 4: Conversion et sauvegarde du fichier\n",
    "    # L'audio arrive du navigateur en format webm/opus, il faut le convertir en WAV.\n",
    "    try:\n",
    "        # Utilisation de ffmpeg pour la conversion en mémoire\n",
    "        proc = (\n",
    "            ffmpeg\n",
    "            .input('pipe:0')\n",
    "            .output('pipe:1', format='wav')\n",
    "            .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True)\n",
    "        )\n",
    "        out, err = proc.communicate(input=audio_data)\n",
    "\n",
    "        # Lire les données WAV converties\n",
    "        rate, data = read(io.BytesIO(out))\n",
    "\n",
    "        # Sauvegarder le fichier WAV\n",
    "        write(filename, rate, data)\n",
    "        print(f\"Fichier audio sauvegardé sous le nom : {filename}\")\n",
    "        return filename\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"Erreur ffmpeg (assurez-vous que ffmpeg est installé) :\")\n",
    "        print(e.stderr.decode())\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5QHDLpV8YXP"
   },
   "outputs": [],
   "source": [
    "def generer_playlist_audio():\n",
    "  audio_filename = record_audio()\n",
    "  genre =  genre_decoding(p_vote_maj(Votes_of(models_Genres_probas_of([audio_filename], \"paths\"))))\n",
    "  mood =  mood_decoding(p_vote_maj(Votes_of(models_Moods_probas_of([audio_filename], \"paths\"))))\n",
    "  df =  filtered_df = filtered_df = df[\n",
    "    (df['mood'].str.lower() == mood.lower()) &\n",
    "    (df['genre'].str.lower() == genre.lower())\n",
    "]\n",
    " # Tirage aléatoire de n morceaux (ou moins si pas assez)\n",
    "  playlist = filtered_df.sample(n=min(15, len(filtered_df)), random_state=42)\n",
    "  return playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGQtF70mnvev"
   },
   "source": [
    "# PHASE 3 : Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5T5K7ZgOkA-u"
   },
   "source": [
    "### PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjqXyS4vkC59",
    "outputId": "6dcb1dea-f04e-4a20-89df-907c88f4de5d"
   },
   "outputs": [],
   "source": [
    "# 3 ----------\n",
    "dataset_path = \"/content/drive/MyDrive/Artishow/Data/genres_original\"\n",
    "subfolders = os.listdir(dataset_path)\n",
    "print(\"Sous-dossiers:\", subfolders)\n",
    "audio_files = glob.glob(f\"{dataset_path}/**/*.wav\", recursive=True)\n",
    "# 4 ----------\n",
    "genre_mapping = {0: 'blues', 1: 'classical', 2: 'country', 3: 'disco', 4: 'hiphop', 5: 'jazz', 6: 'metal', 7: 'pop', 8: 'reggae', 9: 'rock'}\n",
    "model_mapping = {1:\"SVM\", 2:\"Logistic Regression\", 3:\"Random Forest\", 4:\"Gradient Boosting\", 5:\"K-Nearest Neighbors\", 6:\"VGG-16\"}\n",
    "inv_genre_mapping = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiSdzNcBkPa-"
   },
   "outputs": [],
   "source": [
    "#deezer\n",
    "import requests\n",
    "import io\n",
    "def load_audio_from_url(url, sr=22050, duration=30):\n",
    "    response = requests.get(url)\n",
    "    audio_bytes = io.BytesIO(response.content)\n",
    "    y, sr = librosa.load(audio_bytes, sr=sr, duration=duration)\n",
    "    return y, sr\n",
    "\n",
    "# X / features\n",
    "def Features(y, duration=30, sr=22050):\n",
    "  def stats(feature):\n",
    "      return list(map(float, np.mean(feature, axis=1))) + list(map(float, np.std(feature, axis=1)))\n",
    "  # Extraction des features\n",
    "  mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "  rms = librosa.feature.rms(y=y)\n",
    "  spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "  bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "  contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "  flatness = librosa.feature.spectral_flatness(y=y)\n",
    "  rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "  tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "  zero_crossing = librosa.feature.zero_crossing_rate(y=y)\n",
    "  tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "  features = []\n",
    "  for f in [mfcc, rms, spectral_centroid, bandwidth, contrast, flatness, rolloff, tonnetz, zero_crossing]:\n",
    "      features.extend(stats(f))\n",
    "  features.append(float(tempo))\n",
    "  return features\n",
    "\n",
    "def Features_of(container, category, duration=30, sr=22050):\n",
    "  print('Extracting features :', end='')\n",
    "  N_f = len(container)\n",
    "  X = [] # features\n",
    "  Y = [] # genres\n",
    "  for i in range(N_f):\n",
    "    if category == \"paths\":\n",
    "      path = container[i]\n",
    "      y, sr = librosa.load(path, sr=sr, duration=duration)\n",
    "    elif category == \"urls\":\n",
    "      url = container[i]\n",
    "      y, sr = load_audio_from_url(url)\n",
    "    features = Features(y)\n",
    "    X.append(features)\n",
    "    print(f'{i+1}✓', end='')\n",
    "  print('')\n",
    "  return X\n",
    "\n",
    "def gtzan_Genres_of(files, duration=30, sr=22050):\n",
    "  print('Extracting genres :', end='')\n",
    "  N_f = len(files)\n",
    "  X = [] # features\n",
    "  Y = [] # genres\n",
    "  for i in range(N_f):\n",
    "    file_path = files[i]\n",
    "    genre = (os.path.splitext(os.path.basename(file_path))[0]).split('.')[0]\n",
    "    Y.append(genre)\n",
    "    print(f'{i+1}✓', end='')\n",
    "  print('')\n",
    "  return Y\n",
    "\n",
    "def Genres_of(genres, duration=30, sr=22050):\n",
    "  return [inv_genre_mapping[g] for g in genres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4k5fMATAkSmQ",
    "outputId": "ad3379b3-7cb2-4d43-d224-1cebbfca37b2"
   },
   "outputs": [],
   "source": [
    "# Fichier Pré-entraînés 80-20 F_gtzan\n",
    "import joblib\n",
    "Xe1 = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/X_train.pkl')\n",
    "Ye1 = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/Y_train.pkl')\n",
    "Xt1 = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/X_test.pkl')\n",
    "Yt1 = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/Y_test.pkl')\n",
    "print(Ye1) # si pbm Artishow/Modèle/Saves contient les bons pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "HuS6TGrEkTii",
    "outputId": "4101c490-5c0d-4ccf-8cd7-93939d60a714"
   },
   "outputs": [],
   "source": [
    "# Entrainement Classifiers\n",
    "# ML ----------------------------------------\n",
    "from time import sleep\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model_svm = SVC(kernel='linear', probability=True)\n",
    "model_svm.fit(Xe1, Ye1)\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(Xe1, Ye1)\n",
    "model_rf = RandomForestClassifier(n_estimators=103, random_state=42)\n",
    "model_rf.fit(Xe1, Ye1)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(Xe1, Ye1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZfU3N7_kX7x"
   },
   "outputs": [],
   "source": [
    "def models_Genres_probas_of(container, category):\n",
    "  scaler = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/scaler.pkl')\n",
    "  X = Features_of(container, category) #généralisé\n",
    "  X = scaler.transform(X)\n",
    "  Y_probas_svm = model_svm.predict_proba(X)\n",
    "  Y_probas_lr = model_lr.predict_proba(X)\n",
    "  Y_probas_rf = model_rf.predict_proba(X)\n",
    "  Y_probas_knn = model_knn.predict_proba(X)\n",
    "  P = []\n",
    "  for i in range(len(container)):\n",
    "    PP = [] # pour chaque musique\n",
    "    PP.append(Y_probas_svm[i]) #tableau de probas : pour 1 file\n",
    "    PP.append(Y_probas_lr[i])\n",
    "    PP.append(Y_probas_rf[i])\n",
    "    PP.append(Y_probas_knn[i])\n",
    "    #PP est un tableau de tableaux de probas : pour 1 file\n",
    "    P.append(PP)\n",
    "  return P #tableau de même longueur que files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdyuXVVHkaiE"
   },
   "outputs": [],
   "source": [
    "def pos_max(t):\n",
    "  p1 = 0\n",
    "  for i in range(len(t)):\n",
    "    if t[i]>t[p1]:\n",
    "      p1 = i\n",
    "  return p1\n",
    "\n",
    "def Votes_of(P):\n",
    "  N_f = len(P) #nombre de files\n",
    "  N_m = len(P[0]) #nombre de modèles\n",
    "  V = []\n",
    "  for i in range(N_f):\n",
    "    VV = []\n",
    "    for j in range(N_m):\n",
    "      VV.append(pos_max(P[i][j]))\n",
    "    V.append(VV)\n",
    "  return V\n",
    "\n",
    "def p_vote_maj(V): #prédiction\n",
    "  N_f = len(V) #nombre de files\n",
    "  N_m = len(V[0]) #nombre de modèles\n",
    "  Y = [] # Genres\n",
    "  for i in range(N_f):\n",
    "      total_par_genre = [0 for k in range(len(genre_mapping))]\n",
    "      for j in range(N_m):\n",
    "          total_par_genre[V[i][j]] += 1\n",
    "      g = pos_max(total_par_genre)\n",
    "      Y.append(g)\n",
    "  return Y\n",
    "\n",
    "\n",
    "def genre_decoding(t):\n",
    "  t2 = []\n",
    "  for i in range(len(t)):\n",
    "    t2.append(genre_mapping[t[i]])\n",
    "  return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3sYx8sJk2OG"
   },
   "source": [
    "### Moods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZICx_Uhek37z"
   },
   "outputs": [],
   "source": [
    "mood_mapping = {0: 'dark', 1: 'deep', 2: 'dream', 3: 'emotional', 4: 'epic', 5: 'happy', 6: 'motivational', 7: 'relaxing', 8: 'romantic', 9: 'sad'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMJ705yilD_2",
    "outputId": "f7950cea-3b64-4890-cf69-b1a247990437"
   },
   "outputs": [],
   "source": [
    "# Fichier Pré-entraînés 80-20 F_gtzan\n",
    "import joblib\n",
    "We1 = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/X_train.pkl')\n",
    "Me1 = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/Y_train.pkl')\n",
    "Wt1 = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/X_test.pkl')\n",
    "Mt1 = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/Y_test.pkl')\n",
    "print(Ye1) # si pbm Artishow/Modèle/Saves contient les bons pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "jSrK-eK2lGgK",
    "outputId": "296848a7-887f-4f3a-e91d-333ae293e902"
   },
   "outputs": [],
   "source": [
    "# Entrainement Classifiers (1)\n",
    "# ML ----------------------------------------\n",
    "mood_svm = SVC(kernel='linear', probability=True)\n",
    "mood_svm.fit(We1, Me1)\n",
    "mood_lr = LogisticRegression()\n",
    "mood_lr.fit(We1, Me1)\n",
    "mood_rf = RandomForestClassifier(n_estimators=103, random_state=42)\n",
    "mood_rf.fit(We1, Me1)\n",
    "mood_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "mood_knn.fit(We1, Me1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywentBSrlcBw"
   },
   "outputs": [],
   "source": [
    "def models_Moods_probas_of(container, category):\n",
    "  scaler = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/scaler.pkl')\n",
    "  X = Features_of(container, category) #généralisé\n",
    "  X = scaler.transform(X)\n",
    "  Y_probas_svm = mood_svm.predict_proba(X)\n",
    "  Y_probas_lr = mood_lr.predict_proba(X)\n",
    "  Y_probas_rf = mood_rf.predict_proba(X)\n",
    "  Y_probas_knn = mood_knn.predict_proba(X)\n",
    "  P = []\n",
    "  for i in range(len(container)):\n",
    "    PP = []\n",
    "    PP.append(Y_probas_svm[i]) #tableau de probas : pour 1 file\n",
    "    PP.append(Y_probas_lr[i])\n",
    "    PP.append(Y_probas_rf[i])\n",
    "    PP.append(Y_probas_knn[i])\n",
    "    P.append(PP)\n",
    "  return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqGayAyZlgV5"
   },
   "outputs": [],
   "source": [
    "def mood_decoding(t):\n",
    "  t2 = []\n",
    "  for i in range(len(t)):\n",
    "    t2.append(mood_mapping[t[i]])\n",
    "  return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AbZVufewIPy"
   },
   "source": [
    "### Etiquettage - Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3axK-st986uV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def extract_track_id(filepath):\n",
    "    # Vérifier que filepath existe et est un fichier\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(f\"Attention : '{filepath}' n'est pas un fichier valide.\")\n",
    "        return None\n",
    "\n",
    "    filename = os.path.basename(filepath)  # extrait le nom de fichier\n",
    "    try:\n",
    "        # Supposons que l'ID est la première partie avant un '_'\n",
    "        track_id_str = filename.split('_')[0]\n",
    "        track_id = int(track_id_str)  # convertir en int\n",
    "        return track_id\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur extraction ID dans '{filename}': {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6Yom6sa8-xM"
   },
   "outputs": [],
   "source": [
    "def f_mood_tristan(track_id):\n",
    "  return mood_decoding(p_vote_maj(Votes_of(models_Moods_probas_of(audio_files[:2], \"paths\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzbiV2E09cKU"
   },
   "outputs": [],
   "source": [
    "def mood_for_song(filepath):\n",
    "  return f_mood_tristan(extract_track_id(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "wpTfdDBecQfM",
    "outputId": "34c501a7-5b75-496e-db03-e2eab2e60965"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('/content/drive/MyDrive/Artishow/Modèle/ML/knn_model.pkl')\n",
    "files.download('/content/drive/MyDrive/Artishow/Modèle/ML_moods/scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfpKdjJ2cQIW"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9ps8LDuSkMC"
   },
   "outputs": [],
   "source": [
    "knn_model = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML/knn_model.pkl')\n",
    "scaler = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/scaler.pkl')\n",
    "\n",
    "def pred_musique_mood_knn(file_path):\n",
    "  extract_features(file_path, duration=30, sr=22050)\n",
    "  df_test = pd.DataFrame(X)\n",
    "  scaler = joblib.load('/content/drive/MyDrive/Artishow/Modèle/ML_moods/scaler.pkl')\n",
    "  df_test_scaled = scaler.transform(df_test)\n",
    "  prediction = knn_model.predict(df_test_scaled)\n",
    "  print(f\"Prédiction (Mood) : {mood_mapping[int(prediction[0])]}\")\n",
    "  X.clear()\n",
    "  return mood_mapping[int(prediction[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6g4CAOEM89Rz",
    "outputId": "20d60460-850e-4b82-e72f-811f51e27dae"
   },
   "outputs": [],
   "source": [
    "df_audio['mood'] = df_audio['filepath'].apply(pred_musique_mood_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4sRlsr6TQgN"
   },
   "outputs": [],
   "source": [
    "df_audio.to_csv('/content/drive/MyDrive/Artishow/Modèle/df_audio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "awimKiCqVFSW",
    "outputId": "3507592c-f8b7-4adb-ad9d-ebaac8eeaaab"
   },
   "outputs": [],
   "source": [
    "df_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7P14mGo--CJg",
    "outputId": "5a30e3b4-883f-4343-f46d-de0dc206ef4d"
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def mood_for_song(filepath):\n",
    "    # ta fonction d'extraction mood, par exemple :\n",
    "    track_id = extract_track_id(filepath)\n",
    "    if track_id is None:\n",
    "        return None\n",
    "    return f_mood_tristan(track_id)\n",
    "\n",
    "filepaths = df_audio['filepath'].tolist()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    moods = list(executor.map(mood_for_song, filepaths))\n",
    "\n",
    "df_audio['mood'] = moods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "j7FhsIxjE5-l",
    "outputId": "20a03da5-01e6-4b58-949d-8c261eef5fb2"
   },
   "outputs": [],
   "source": [
    "df_audio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Akse2ok4E_-L",
    "outputId": "a6b14a7a-15fb-435d-e973-90b1c4119647"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "\n",
    "\n",
    "\n",
    "# --- ÉTAPE 2 : Définir le chemin et sauvegarder ---\n",
    "\n",
    "# Définissez où vous voulez sauvegarder le fichier et quel nom lui donner.\n",
    "# '/content/drive/MyDrive/' est le chemin vers la racine de \"Mon Drive\".\n",
    "# Vous pouvez aussi créer des sous-dossiers, ex: '/content/drive/MyDrive/MonProjet/donnees_traitees.csv'\n",
    "nom_du_fichier = 'df_audio.csv'\n",
    "chemin_de_sauvegarde = f'/content/drive/MyDrive/Artishow/{nom_du_fichier}'\n",
    "\n",
    "print(f\"\\nSauvegarde du DataFrame vers : {chemin_de_sauvegarde}\")\n",
    "\n",
    "# On utilise la fonction to_csv()\n",
    "# df_audio est le nom de votre DataFrame\n",
    "# index=False est TRÈS important pour éviter de sauvegarder l'index de Pandas\n",
    "# dans une colonne inutile.\n",
    "try:\n",
    "    df_audio.to_csv(chemin_de_sauvegarde, index=False)\n",
    "    print(\"\\n✅ Sauvegarde terminée avec succès !\")\n",
    "    print(f\"Vous pouvez trouver votre fichier '{nom_du_fichier}' à la racine de votre Google Drive.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Une erreur est survenue lors de la sauvegarde : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lr2mNAmv6FXF"
   },
   "outputs": [],
   "source": [
    "df_audio = pd.read_csv('/content/drive/MyDrive/Artishow/df_audio.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_GX7XRt4hYdR",
    "mxz__6ejiJAJ",
    "IU2Vj7KViOM6",
    "YYaFGNiqiVgz",
    "oGfU9T28idlQ",
    "qtRRFncZn589",
    "xeHW8wFO16Wp",
    "HuLYtN3En8if",
    "DcCehqTTncMS",
    "njju_yyBpZjA",
    "w09QkToHphoC",
    "UlLQ7l74nhOm",
    "-7YGtwymPfIo",
    "FOgz_9v2M6Yc",
    "6o_BqblzNXvv",
    "xPLBqgu7znaO",
    "_E_bEqthORCH",
    "X0Okv--u6pt0",
    "TLSjtVME7PcW",
    "LaG7yQf77zvS",
    "935Kvvrp8HSI",
    "FGQtF70mnvev",
    "5T5K7ZgOkA-u",
    "_3sYx8sJk2OG",
    "3AbZVufewIPy"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
